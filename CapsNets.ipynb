{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-4141630e56b4>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\amogh\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\amogh\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\amogh\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\amogh\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\amogh\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 5\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = mnist.train.images[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, 6, 1], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
    "caps1_n_dims = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keepdims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_n_caps = 10\n",
    "caps2_n_dims = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'W_tiled:0' shape=(?, 1152, 10, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps1_output_tiled:0' shape=(?, 1152, 10, 8, 1) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps1_output_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_predicted:0' shape=(?, 1152, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_weights = tf.nn.softmax(raw_weights, axis=2, name=\"routing_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_round_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_predicted:0' shape=(?, 1152, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_round_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
    "                             name=\"raw_weights_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output = caps2_output_round_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_proba_1:0' shape=(?, 1, 1) dtype=int64>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session():\n",
    "    print(T.eval(feed_dict={y: np.array([0, 1, 2, 3, 9])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 10),\n",
    "                           name=\"present_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 10),\n",
    "                          name=\"absent_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reconstruction_mask:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_masked:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_input:0' shape=(?, 160) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 98.8200%  Loss: 0.015530 (improved)\n",
      "Epoch: 2  Val accuracy: 99.1800%  Loss: 0.010722 (improved)\n",
      "Epoch: 3  Val accuracy: 99.3200%  Loss: 0.008615 (improved)\n",
      "Epoch: 4  Val accuracy: 99.3600%  Loss: 0.008465 (improved)\n",
      "Epoch: 5  Val accuracy: 99.2600%  Loss: 0.007841 (improved)\n",
      "Epoch: 6  Val accuracy: 99.3600%  Loss: 0.007396 (improved)\n",
      "Epoch: 7  Val accuracy: 99.3000%  Loss: 0.007972\n",
      "Epoch: 8  Val accuracy: 99.4000%  Loss: 0.007599\n",
      "Epoch: 9  Val accuracy: 99.3200%  Loss: 0.008151\n",
      "Epoch: 10  Val accuracy: 99.3200%  Loss: 0.008229\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
    "n_iterations_validation = mnist.validation.num_examples // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        # At the end of each epoch,\n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "Final test accuracy: 99.3200%  Loss: 0.007657   \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = mnist.test.num_examples // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
